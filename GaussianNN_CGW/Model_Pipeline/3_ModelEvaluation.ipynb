{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook evaluates the final trained model on the test set.\n",
    "\n",
    "**Pipeline:**\n",
    "- Load the trained model from `2_TrainBestModel.ipynb`\n",
    "- Evaluate on test set\n",
    "- Generate comprehensive evaluation metrics\n",
    "- Create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n",
    "\n",
    "from astroML.classification import GMMBayes\n",
    "from astroML.datasets import fetch_rrlyrae_combined\n",
    "from astroML.utils import split_samples\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "from astropy.io import ascii\n",
    "from astropy.io import fits\n",
    "import os.path\n",
    "\n",
    "from astropy.table import Table, join, MaskedColumn, vstack, Column\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from astropy.table import vstack\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import math\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paths_header",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir_path = \"/Users/howard_willard/Desktop/TESS_Cluster_Age_ML/GaussianNN_CGW/Model_Pipeline/\"\n",
    "temp_files_path = project_dir_path + 'TempFiles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_header",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "save_path = temp_files_path\n",
    "file_name = 'traintest_data2.pkl'\n",
    "\n",
    "with open(save_path + file_name, 'rb') as f:\n",
    "    PROCESSED_DATASET = pickle.load(f)\n",
    "\n",
    "(   X_train, X_test, \n",
    "    period_train, period_test, \n",
    "    y_train, y_test, \n",
    "    feature_cols, SCALER, y_mean,\n",
    "    train_cluster_names, test_cluster_names) = PROCESSED_DATASET\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET LOADED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"Test set:       {X_test.shape[0]} samples\")\n",
    "print(f\"Features:       {X_train.shape[1]} summary statistics\")\n",
    "print(f\"Periodogram:    {period_train.shape[1]} frequency bins\")\n",
    "print(f\"\\nTest clusters:  {len(np.unique(test_cluster_names))} unique clusters\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_model_header",
   "metadata": {},
   "source": [
    "# Load Model Architecture and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model_class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model class definition\n",
    "import sys\n",
    "sys.path.append(project_dir_path)\n",
    "\n",
    "from GaussianNN_wPeriodogram import DualInputNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload - automatically reloads modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "# Import evaluation functions\n",
    "from DataAnalysis_HelperFcns import (\n",
    "    mae, rmse, coverage, crps_gaussian, Loss_Components\n",
    ")\n",
    "\n",
    "from SingleFold_PlottingFcns import (\n",
    "    SummaryStats, PlotSummaryStats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_trained_model_header",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_trained_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD TRAINED MODEL\n",
    "# ============================================================\n",
    "\n",
    "model_path = temp_files_path + 'final_model.pt'\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "model_package = torch.load(model_path)\n",
    "\n",
    "# Extract model components\n",
    "hyperparameters = model_package['hyperparameters']\n",
    "model_architecture = model_package['model_architecture']\n",
    "training_log = model_package['training_log']\n",
    "best_epoch = model_package['best_epoch_from_tuning']\n",
    "composite_score = model_package['composite_score']\n",
    "\n",
    "# Display model information\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINED MODEL LOADED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best epoch (from tuning): {best_epoch}\")\n",
    "print(f\"Composite score:          {composite_score:.4f}\")\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Summary stats dim:      {model_architecture['summary_dim']}\")\n",
    "print(f\"  Periodogram dim:        {model_architecture['periodogram_dim']}\")\n",
    "print(f\"  Hidden layer size:      {model_architecture['hidden_size']}\")\n",
    "print(f\"  Dropout probability:    {model_architecture['dropout_prob']}\")\n",
    "print(f\"  Use periodogram:        {model_architecture['use_periodogram']}\")\n",
    "print(f\"  Use CNN:                {model_architecture['use_cnn']}\")\n",
    "print(f\"  Learn sigma:            {model_architecture['learn_sigma']}\")\n",
    "print(\"\\nHyperparameters:\")\n",
    "for key, value in hyperparameters.items():\n",
    "    print(f\"  {key:30s} = {value}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reconstruct_model_header",
   "metadata": {},
   "source": [
    "# Reconstruct Model from Saved Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reconstruct_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RECONSTRUCT MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Reconstructing model from saved weights...\")\n",
    "\n",
    "# Initialize model with saved architecture\n",
    "final_model = DualInputNN(\n",
    "    summary_dim=model_architecture['summary_dim'],\n",
    "    periodogram_dim=model_architecture['periodogram_dim'],\n",
    "    x1=model_architecture['hidden_size'],\n",
    "    dropout_prob=model_architecture['dropout_prob'],\n",
    "    use_periodogram=model_architecture['use_periodogram'],\n",
    "    periodogram_use_cnn=model_architecture['use_cnn'],\n",
    "    learn_sigma=model_architecture['learn_sigma']\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "final_model.load_state_dict(model_package['model_state_dict'])\n",
    "\n",
    "# Set to evaluation mode\n",
    "final_model.eval()\n",
    "\n",
    "print(\"\\nâœ… Model reconstructed and ready for evaluation!\")\n",
    "print(f\"   Model is in evaluation mode (dropout disabled)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placeholder_header",
   "metadata": {},
   "source": [
    "# Evaluation Sections (To Be Implemented)\n",
    "\n",
    "The following sections will be added:\n",
    "1. Test set predictions\n",
    "2. Summary statistics\n",
    "3. Prediction vs truth plots\n",
    "4. Uncertainty calibration analysis\n",
    "5. Residual analysis\n",
    "6. Performance by cluster properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placeholder_cell",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
