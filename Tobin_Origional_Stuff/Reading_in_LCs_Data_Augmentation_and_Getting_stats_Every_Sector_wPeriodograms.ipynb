{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4654de1-e32c-4e8b-9aad-aebf380d60d8",
   "metadata": {},
   "source": [
    "Notebook original written by Tobin Wainer\n",
    "\n",
    "Modified by Charlie Willard to output the Periodograms\n",
    "\n",
    "CW also included some visualization cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8071621e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01melk\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnsembleLC\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightcurve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasicLightcurve\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elk'"
     ]
    }
   ],
   "source": [
    "import astropy.units as u\n",
    "import numpy as np\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.coordinates as coord\n",
    "\n",
    "from astropy.io import ascii\n",
    "from astropy.io import fits\n",
    "import os.path\n",
    "# \n",
    "import elk\n",
    "from elk.ensemble import EnsembleLC\n",
    "from elk.lightcurve import BasicLightcurve\n",
    "\n",
    "from astropy.table import Table, join, MaskedColumn, vstack, Column\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abad82-2786-4d39-a49b-93e89d0cd51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03887ae-a85d-45f9-9149-d43de1447491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('cluster_names.txt', 'r')\n",
    "names = f.readlines()\n",
    "cnames = []\n",
    "for i in names:\n",
    "    t = i.split('\\n')[0]\n",
    "    cnames.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8627e74c-4854-4fe4-8a24-a503536963b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/uufs/astro.utah.edu/common/home/u1363702/notebooks/tess_clusters/TESS_Cluster_Age_ML'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9daa41-5261-457f-a4bc-57efed645cba",
   "metadata": {},
   "source": [
    "# Set Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f17ab26-37c6-4eaa-b6e5-bf8fe0091cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_sectors = True\n",
    "# use_half_sectors = True\n",
    "use_12day_rolling_window = False\n",
    "use_stiched_sectors = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d3f2a-0379-484e-b388-2d93aa76c0d2",
   "metadata": {},
   "source": [
    "# Load the Lightcure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4becb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path='/uufs/chpc.utah.edu/common/home/astro/zasowski/sinha/tess_data/light_curves/resampled_fits_tables/'\n",
    "# filenames =  [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(path+\"/\")) for f in fn]\n",
    "filenames = glob.glob(path + '*.fits')\n",
    "# gal_list=['MW', 'LMC', 'SMC']\n",
    "\n",
    "l_of_cs=[]\n",
    "for file in filenames:\n",
    "    data = elk.ensemble.from_fits(file)\n",
    "    l_of_cs.append(elk.ensemble.from_fits(file))\n",
    "\n",
    "\n",
    "# for gal in gal_list:\n",
    "    \n",
    "    # # Build the full base directory path, expanding the user (~)\n",
    "    # base_path = os.path.expanduser(path + \"/\")\n",
    "    \n",
    "    # # Initialize an empty list to hold full file paths\n",
    "    # filenames = []\n",
    "\n",
    "    # # Walk through all directories and subdirectories starting at base_path\n",
    "    # for dirpath, dirnames, files in os.walk(base_path):\n",
    "    #     # For each file in the current directory\n",
    "    #     for filename in files:\n",
    "    #         # Join directory path and filename to get the full file path\n",
    "    #         full_path = os.path.join(dirpath, filename)\n",
    "    #         # Add the full path to the list\n",
    "    #         filenames.append(full_path)\n",
    "\n",
    "    # print(filenames)\n",
    "    # filenames =  [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(path+gal+\"/\")) for f in fn]\n",
    "    # # print(filenames)\n",
    "\n",
    "    # for file in filenames:\n",
    "    #     l_of_cs.append(elk.ensemble.from_fits(file))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aceb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_of__all_lcs=[]\n",
    "for i in range(len(l_of_cs)):\n",
    "    data = []\n",
    "    med = 0\n",
    "    for j in range(len(l_of_cs[i].lcs)):\n",
    "        lc = l_of_cs[i].lcs[j].corrected_lc\n",
    "        if j == 0:\n",
    "            med = np.nanmedian(lc['flux'])\n",
    "        else:\n",
    "            delta = np.nanmedian(lc['flux']) - med\n",
    "            lc['flux'] = lc['flux'] - delta\n",
    "        data.append(lc)\n",
    "    stitched_data = vstack(data)\n",
    "    l_of__all_lcs.append(stitched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l_of__all_lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e30b8-63fb-429a-afaa-c4fa1aaf9855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#l_of__all_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bb912-f9e9-4f51-b412-c06b631311e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 1):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.scatter(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value, s=1)\n",
    "    plt.plot(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e594a-657a-4fb0-8c66-db769e923d06",
   "metadata": {},
   "source": [
    "# Bin into 12 Day Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_lcs=[]\n",
    "\n",
    "for i in range(len(l_of__all_lcs)):\n",
    "\n",
    "    if use_full_sectors:\n",
    "        data_augmented_lcs.append(l_of__all_lcs[i])\n",
    "\n",
    "    # if use_half_sectors:\n",
    "    #     #Split each light curve (ie sector) in half, therefore taking ~12 day windows in the lc:\n",
    "    #     data_augmented_lcs.append(l_of__all_lcs[i][:int(len(l_of__all_lcs[i])/2)])\n",
    "    #     data_augmented_lcs.append(l_of__all_lcs[i][int(len(l_of__all_lcs[i])/2):])\n",
    "    \n",
    "    #if use_stiched_sectors:\n",
    "        # stich together lightcurves.\n",
    "        # if names are the same, vstack\n",
    "        # make sure time order is preserved.\n",
    "        \n",
    "    #if use_12day_rolling_window:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd640030",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_augmented_lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71ef5b-c490-476b-97f6-2ec780cbacfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(6):\n",
    "    i = random.randint(0, len(data_augmented_lcs) - 1)\n",
    "    print(len(data_augmented_lcs[i]['time']))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.scatter(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value, s=1)\n",
    "    t = data_augmented_lcs[i]['time'].value\n",
    "    f = data_augmented_lcs[i]['flux'].value\n",
    "    plt.plot(t-t[0], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af4e18-30b6-4ad7-a125-f708e9f23c21",
   "metadata": {},
   "source": [
    "# Add Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "\n",
    "for i in range(len(l_of_cs)):\n",
    "    j=0\n",
    "    # while j < (len(l_of_cs[i].lcs)):\n",
    "\n",
    "    if use_full_sectors:\n",
    "        names.append(l_of_cs[i].callable)\n",
    "        \n",
    "        # if use_half_sectors:\n",
    "        #     names.append(l_of_cs[i].callable) \n",
    "        #     names.append(l_of_cs[i].callable)\n",
    "        \n",
    "    j+=1\n",
    "        \n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11311bb-86f6-40bf-bc13-8e6231d7dd3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f15c824-f56e-451d-9a90-effd0f3b21e5",
   "metadata": {},
   "source": [
    "# Get Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroML.datasets import fetch_sdss_galaxy_images, fetch_LINEAR_sample, fetch_LINEAR_geneva\n",
    "from astroML.utils import split_samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.special import entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# l_of_stat_tables=[]\n",
    "\n",
    "# for i in range(len(data_augmented_lcs)):\n",
    "    \n",
    "#     lc=BasicLightcurve(data_augmented_lcs[i]['time'], data_augmented_lcs[i]['flux'], \n",
    "#                     data_augmented_lcs[i]['flux_err'], sector=99)\n",
    "    \n",
    "#     lc.get_stats_using_defaults()\n",
    "\n",
    "#     table=lc.get_stats_table(names[i])['name',\n",
    "#      'rms',\n",
    "#      'std',\n",
    "#      'MAD',\n",
    "#      'sigmaG',\n",
    "#      'skewness',\n",
    "#      'von_neumann_ratio',\n",
    "#      'J_Stetson',\n",
    "#      'max_power',\n",
    "#      'freq_at_max_power',\n",
    "#      'n_peaks',\n",
    "#      'ratio_of_power_at_high_v_low_freq',\n",
    "#      'FAP',\n",
    "#      'max_autocorrelation',\n",
    "#      'time_of_max_autocorrelation']\n",
    "    \n",
    "\n",
    "#     # (1/np.arange(0.04, 11, 0.01) --> spacing of frequency bins\n",
    "#     # here 0.04 --> 11 in days\n",
    "#     # 1/time = frequency\n",
    "#     # 0.01 spacing is fine for single\n",
    "#     # sampling should be proportional to # days in lightcurve\n",
    "#     # 0.0001 = 6 sectors\n",
    "#     # 0.00001 is the max probs?\n",
    "\n",
    "#     periodogram = lc.periodogram\n",
    "#     frequency_list = 1/np.arange(0.04, 11, 0.01)\n",
    "    \n",
    "#     sum_LSP_power_10_7_days = np.sum(periodogram[np.where((frequency_list < 10) & (frequency_list > 7))])\n",
    "#     sum_LSP_power_7_4_days  = np.sum(periodogram[np.where((frequency_list < 7)  & (frequency_list > 4))])\n",
    "#     sum_LSP_power_4_1_days  = np.sum(periodogram[np.where((frequency_list < 4)  & (frequency_list > 1))])            \n",
    "#     sum_LSP_power_1_p5_days = np.sum(periodogram[np.where((frequency_list < 1)  & (frequency_list > .5))])        \n",
    "\n",
    "#     # sum_LSP_power_10_7_days = np.sum(lc.periodogram[np.where((1/np.arange(0.04, 11, 0.01) < 10) &\n",
    "#     #                                                                                      (1/np.arange(0.04, 11, 0.01) > 7))])\n",
    "#     # sum_LSP_power_7_4_days = np.sum(lc.periodogram[np.where((1/np.arange(0.04, 11, 0.01) < 7) &\n",
    "#     #                                                                                      (1/np.arange(0.04, 11, 0.01) > 4))])\n",
    "#     # sum_LSP_power_4_1_days = np.sum(lc.periodogram[np.where((1/np.arange(0.04, 11, 0.01) < 4) &\n",
    "#     #                                                                                      (1/np.arange(0.04, 11, 0.01) > 1))])            \n",
    "#     # sum_LSP_power_1_p5_days = np.sum(lc.periodogram[np.where((1/np.arange(0.04, 11, 0.01) < 1) &\n",
    "#     #                                                                                      (1/np.arange(0.04, 11, 0.01) > .5))])        \n",
    "\n",
    "#     entropy = entr(data_augmented_lcs[i]['flux'].value).sum()\n",
    "    \n",
    "#     table.add_column(Column(sum_LSP_power_10_7_days), name='SumLSP_10_7_Day_Power')\n",
    "#     table.add_column(Column(sum_LSP_power_7_4_days), name='SumLSP_7_4_Day_Power')\n",
    "#     table.add_column(Column(sum_LSP_power_4_1_days), name='SumLSP_4_1_Day_Power')\n",
    "#     table.add_column(Column(sum_LSP_power_1_p5_days), name='SumLSP_1_p5_Day_Power')\n",
    "#     table.add_column(Column(entropy), name='Entropy')\n",
    "    \n",
    "    # l_of_stat_tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963068a-3690-426d-b25f-b0c4b0cbeafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Column\n",
    "from scipy.stats import entropy as entr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609c7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "l_of_stat_tables = []\n",
    "\n",
    "import sys\n",
    "\n",
    "# Start timer before the loop\n",
    "start_time = time.time()\n",
    "\n",
    "def print_progress_bar(i, total, length=30, start_time=None):\n",
    "    percent = i / total\n",
    "    filled = int(length * percent)\n",
    "    bar = 'â–ˆ' * filled + '-' * (length - filled)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    if i > 0:\n",
    "        eta = (elapsed / i) * (total - i)\n",
    "        eta_str = time.strftime(\"%H:%M:%S\", time.gmtime(eta))\n",
    "    else:\n",
    "        eta_str = \"--:--:--\"\n",
    "\n",
    "    sys.stdout.write(f'\\rProgress: |{bar}| {round(percent * 100, 1)}% | ETA: {eta_str}')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "for i in range(len(data_augmented_lcs)):\n",
    "    print_progress_bar(i + 1, len(data_augmented_lcs), start_time=start_time)\n",
    "\n",
    "    lc = BasicLightcurve(data_augmented_lcs[i]['time'],\n",
    "                         data_augmented_lcs[i]['flux'],\n",
    "                         data_augmented_lcs[i]['flux_err'],\n",
    "                         sector=99)\n",
    "\n",
    "    lc.get_stats_using_defaults()\n",
    "\n",
    "    table = lc.get_stats_table(names[i])[[\n",
    "        'name',\n",
    "        'rms',\n",
    "        'std',\n",
    "        'MAD',\n",
    "        'sigmaG',\n",
    "        'skewness',\n",
    "        'von_neumann_ratio',\n",
    "        'J_Stetson',\n",
    "        'max_power',\n",
    "        'freq_at_max_power',\n",
    "        'n_peaks',\n",
    "        'ratio_of_power_at_high_v_low_freq',\n",
    "        'FAP',\n",
    "        'max_autocorrelation',\n",
    "        'time_of_max_autocorrelation'\n",
    "    ]]\n",
    "\n",
    "    # Periodogram and frequency grid\n",
    "    frequency_list = 1 / np.arange(0.04, 11, 0.01)\n",
    "    periodogram = lc.periodogram\n",
    "\n",
    "    # Because the lightcurves were smoothed over timescales >10days, don't use those scales.\n",
    "    periodogram = periodogram[(frequency_list < 10)]\n",
    "    frequency_list = frequency_list[(frequency_list < 10)]\n",
    "    \n",
    "    # Sum power in specific period bands\n",
    "    sum_LSP_power_10_7_days = np.sum(periodogram[(frequency_list < 10) & (frequency_list > 7)])\n",
    "    sum_LSP_power_7_4_days  = np.sum(periodogram[(frequency_list < 7) & (frequency_list > 4)])\n",
    "    sum_LSP_power_4_1_days  = np.sum(periodogram[(frequency_list < 4) & (frequency_list > 1)])\n",
    "    sum_LSP_power_1_p5_days = np.sum(periodogram[(frequency_list < 1) & (frequency_list > 0.5)])\n",
    "\n",
    "    # Shannon entropy of the flux\n",
    "    entropy_val = entr(data_augmented_lcs[i]['flux'].value).sum()\n",
    "\n",
    "    # Add new features\n",
    "    table.add_column(Column(sum_LSP_power_10_7_days), name='SumLSP_10_7_Day_Power')\n",
    "    table.add_column(Column(sum_LSP_power_7_4_days), name='SumLSP_7_4_Day_Power')\n",
    "    table.add_column(Column(sum_LSP_power_4_1_days), name='SumLSP_4_1_Day_Power')\n",
    "    table.add_column(Column(sum_LSP_power_1_p5_days), name='SumLSP_1_p5_Day_Power')\n",
    "    table.add_column(Column(entropy_val), name='Entropy')\n",
    "\n",
    "    # NEW: add full periodogram as a variable-length array column\n",
    "    table.add_column(Column([periodogram], name='FullPeriodogram'))\n",
    "\n",
    "    l_of_stat_tables.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08974131",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_table=vstack(l_of_stat_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d94e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f289002-08d9-4ade-b38d-3caf829e2a5a",
   "metadata": {},
   "source": [
    "# Add Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e760738-d2d0-4b2e-a9c1-fd87482ba253",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfe975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_ages\n",
    "# path = '/Users/howard_willard/Desktop/TESS_Cluster_Age_ML-main'\n",
    "# path='/uufs/astro.utah.edu/common/home/u1363702/notebooks/tess_clusters/TESS_Cluster_Age_ML/'\n",
    "# mw=Table.read(path+'/data/Use_MW.fits')\n",
    "# mw\n",
    "\n",
    "# smc=Table.read(path+'/data/Bica_Cut_down.fits')\n",
    "# smc\n",
    "\n",
    "# lmc=Table.read(path+'/data/Glatt_Cut_down.fits')\n",
    "# lmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa348ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages=[]\n",
    "for name in list(stat_table['name']):\n",
    "    for i in range(len(mw)):\n",
    "        if mw[i]['NAME']== name:\n",
    "            ages.append(mw[i]['LOG_AGE'])\n",
    "    \n",
    "    for j in range(len(smc)):\n",
    "        if smc[j]['SimbadName']==name:\n",
    "            ages.append(smc[j]['logAge'])\n",
    "            \n",
    "    for k in range(len(lmc)):\n",
    "        if lmc[k]['SimbadName']==name:\n",
    "            ages.append(lmc[k]['Age'])\n",
    "            \n",
    "len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_table.add_column(Column(ages), name='Lit_Clst_Age', index=1)\n",
    "# path ='/uufs/astro.utah.edu/common/home/u1363702/notebooks/tess_clusters/TESS_Cluster_Age_ML/'\n",
    "# stat_table.write(path+ 'summary_stats.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Table\n",
    "# path ='/uufs/astro.utah.edu/common/home/u1363702/notebooks/tess_clusters/TESS_Cluster_Age_ML/'\n",
    "\n",
    "#stat_table.write(path+'/data/Stats_Table_For_Data_augmented_lcs.fits', overwrite=True)\n",
    "#stat_table.write(path+'/data/Stats_Table_For_all_Clusters_all_sectors_w_entropy_wPeriodogram.fits', overwrite=False)\n",
    "# stat_table.write(path+'/data/Stats_Table_AllClusters_HalfSectors_wPeriodogram.fits', overwrite=True)\n",
    "#stat_table.write(path+'/data/Stats_Table_For_all_Clusters_all_sectors_w_entropy_wPeriodogram.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e2102-2108-4647-9d3e-9ca99bc858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_table[10]['FullPeriodogram']\n",
    "stat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbba477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    i = random.randint(0, len(data_augmented_lcs) - 1)\n",
    "    print(len(data_augmented_lcs[i]['time']))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.scatter(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value, s=1)\n",
    "    x = frequency_list\n",
    "    y = stat_table[i]['FullPeriodogram']\n",
    "    plt.title(str(stat_table[i]['name']))\n",
    "    plt.xscale('log')\n",
    "    plt.plot(x, y/np.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac596a00-40ec-4877-8bfd-aefc779ee706",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_table['FullPeriodogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a18da6-a2b2-4d1f-bcdc-498efb45e1ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from scipy.signal import find_peaks #finds peaks in a perodigram\n",
    "\n",
    "def compute_average_peak_strengths(periodogram_column):\n",
    "    \"\"\"\n",
    "    Computes the average peak strength for each periodogram.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    periodogram_column : astropy.table.Column or np.ndarray\n",
    "        2D array-like object of shape (n_samples, n_freqs)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Array of average peak strengths for each sample.\n",
    "    \"\"\"\n",
    "    periodograms = np.asarray(periodogram_column)  # shape: (N, F)\n",
    "    n_samples = periodograms.shape[0]\n",
    "    peaks = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        pgram = periodograms[i]\n",
    "        peaks[i] = np.max(pgram)\n",
    "        \n",
    "    return np.mean(peaks)\n",
    "\n",
    "mean_peak_strength = compute_average_peak_strengths(stat_table['FullPeriodogram'])\n",
    "print('mean_peak_strength', mean_peak_strength)\n",
    "for _ in range(len(data_augmented_lcs)):\n",
    "    fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "    i = random.randint(0, len(data_augmented_lcs) - 1)\n",
    "    print(len(data_augmented_lcs[i]['time']))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.scatter(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value, s=1)\n",
    "    x = frequency_list\n",
    "    y = stat_table[i]['FullPeriodogram']\n",
    "    axs[0].set_title(str(stat_table[i]['name']))\n",
    "    axs[0].set_xscale('log')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].set_ylim(1e-3, 0.2)\n",
    "    axs[0].plot(x, y)\n",
    "\n",
    "    t = data_augmented_lcs[i]['time'].value\n",
    "    f = data_augmented_lcs[i]['flux'].value\n",
    "    med_dt = np.median(np.diff(t))\n",
    "    axs[1].set_title('lc')\n",
    "    axs[1].plot(t-t[0], f)\n",
    "    axs[1].annotate(f'Median dt {med_dt:.2g} days', xy=(0.7, 0.7), xycoords='axes fraction', ha='center', fontsize=12, color='black')\n",
    "\n",
    "   # plt.vline(10)\n",
    "    # Longer periods means older to zeroth order, for rotational variablility\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd5354-b16f-4cfd-8289-1c4483ba7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_peak_strength = compute_average_peak_strengths(stat_table['FullPeriodogram'])\n",
    "print('mean_peak_strength', mean_peak_strength)\n",
    "\n",
    "num_lcs = 5\n",
    "fig, axs = plt.subplots(num_lcs, 2, figsize=(15, 5*num_lcs))\n",
    "\n",
    "for j in range(num_lcs):\n",
    "    i = random.randint(0, len(data_augmented_lcs) - 1)\n",
    "    print(len(data_augmented_lcs[i]['time']))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    #plt.scatter(l_of__all_lcs[i]['time'].value, l_of__all_lcs[i]['flux'].value, s=1)\n",
    "    x = frequency_list\n",
    "    y = stat_table[i]['FullPeriodogram']\n",
    "    axs[j, 0].set_title(str(stat_table[i]['name'])+', i='+str(i))\n",
    "    axs[j, 0].set_xscale('log')\n",
    "    axs[j, 0].set_yscale('log')\n",
    "    axs[j, 0].set_ylim(1e-3, 0.4)\n",
    "    axs[j, 0].plot(x, y)\n",
    "\n",
    "    t = data_augmented_lcs[i]['time'].value\n",
    "    f = data_augmented_lcs[i]['flux'].value\n",
    "    med_dt = np.median(np.diff(t))\n",
    "    axs[j, 1].set_title('lc')\n",
    "    axs[j, 1].plot(t-t[0], f)\n",
    "    axs[j, 1].annotate(f'Median dt {med_dt:.2g} days', xy=(0.8, 0.9), xycoords='axes fraction', ha='center', fontsize=12, color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17884e-e861-44f8-9b5f-43eef9f2d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grand_plot(\n",
    "    lightcurve_list,\n",
    "    stats_table,\n",
    "    frequency_list,\n",
    "    mode='random_pairs',\n",
    "    num_lcs=5,\n",
    "    cluster_name=None,\n",
    "    random_seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Grand plotting function for lightcurve and periodogram data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lightcurve_list : list of dict\n",
    "        Each dict must have keys: 'time', 'flux'.\n",
    "    stats_table : list of dict\n",
    "        Each dict must have keys: 'name', 'Lit_Clst_Age', 'FullPeriodogram'.\n",
    "    frequency_list : array-like\n",
    "        Frequencies for the periodogram plots.\n",
    "    mode : str\n",
    "        'random_pairs'            -> Random LC/periodogram pairs (default)\n",
    "        'cluster'                  -> All LCs for a given cluster_name\n",
    "        'random_sorted_by_age'     -> Random LCs sorted by age\n",
    "    num_lcs : int\n",
    "        Number of LCs to plot (ignored if mode='cluster' and plotting all from cluster).\n",
    "    cluster_name : str\n",
    "        Cluster to plot if mode='cluster'.\n",
    "    random_seed : int or None\n",
    "        Optional seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    n_lcs = len(lightcurve_list)\n",
    "\n",
    "    # --- Select indices based on mode ---\n",
    "    if mode == 'random_pairs':\n",
    "        indices = random.sample(range(n_lcs), num_lcs)\n",
    "\n",
    "    elif mode == 'cluster':\n",
    "        if cluster_name is None:\n",
    "            raise ValueError(\"Must provide cluster_name when mode='cluster'.\")\n",
    "        indices = [i for i, s in enumerate(stats_table) if s['name'] == cluster_name]\n",
    "        if len(indices) == 0:\n",
    "            raise ValueError(f\"No lightcurves found for cluster '{cluster_name}'.\")\n",
    "        if num_lcs is not None and num_lcs < len(indices):\n",
    "            indices = indices[:num_lcs]\n",
    "\n",
    "    elif mode == 'random_sorted_by_age':\n",
    "        all_indices = random.sample(range(n_lcs), num_lcs)\n",
    "        indices = sorted(all_indices, key=lambda i: stats_table[i]['Lit_Clst_Age'])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose 'random_pairs', 'cluster', or 'random_sorted_by_age'.\")\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, axs = plt.subplots(len(indices), 2, figsize=(15, 5*len(indices)))\n",
    "    if len(indices) == 1:\n",
    "        axs = np.array([axs])  # force 2D shape\n",
    "\n",
    "    for j, i in enumerate(indices):\n",
    "        # Periodogram\n",
    "        x = frequency_list\n",
    "        y = stats_table[i]['FullPeriodogram']\n",
    "        axs[j, 0].set_title(f\"{stats_table[i]['name']}, Age={stats_table[i]['Lit_Clst_Age']}, i={i}\")\n",
    "        axs[j, 0].set_xscale('log')\n",
    "        axs[j, 0].set_yscale('log')\n",
    "        axs[j, 0].set_ylim(1e-3, 0.4)\n",
    "        axs[j, 0].plot(x, y)\n",
    "\n",
    "        # Lightcurve\n",
    "        t = lightcurve_list[i]['time'].value\n",
    "        f = lightcurve_list[i]['flux'].value\n",
    "        med_dt = np.median(np.diff(t))\n",
    "        axs[j, 1].set_title('Lightcurve')\n",
    "        axs[j, 1].plot(t - t[0], f)\n",
    "        axs[j, 1].annotate(f'Median dt {med_dt:.2g} days',\n",
    "                           xy=(0.8, 0.9), xycoords='axes fraction',\n",
    "                           ha='center', fontsize=12, color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccb66a-60c3-4d10-b319-2f8a77374e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(stat_table['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e54d0-0eae-4371-b902-f3c11de6e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_plot(\n",
    "    lightcurve_list=data_augmented_lcs,\n",
    "    stats_table=stat_table,\n",
    "    frequency_list=frequency_list,\n",
    "    #mode='random_pairs',\n",
    "    #mode='cluster',\n",
    "    mode='random_sorted_by_age',\n",
    "    #cluster_name='[SL63] 695',\n",
    "    num_lcs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0dfd59-852b-4d86-b429-63d671bd0edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
